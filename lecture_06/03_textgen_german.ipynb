{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "import numpy as np\n",
    "import fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import attr\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.checkpoint\n",
    "\n",
    "@attr.s(auto_attribs=True, frozen=True)\n",
    "class HParams:\n",
    "    n_vocab: int\n",
    "    n_ctx: int\n",
    "    n_embed: int\n",
    "    n_hidden: int\n",
    "    n_head: int\n",
    "    n_layer: int\n",
    "    gradient_checkpointing: bool\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, hparams: HParams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.wpe = nn.Embedding(hparams.n_ctx, hparams.n_embed)\n",
    "        nn.init.normal_(self.wpe.weight, std=0.01)\n",
    "        self.wte = nn.Embedding(hparams.n_vocab, hparams.n_embed)\n",
    "        nn.init.normal_(self.wte.weight, std=0.02)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Block(hparams) for _ in range(hparams.n_layer)])\n",
    "        self.ln_f = Norm(self.hparams.n_hidden)\n",
    "        if hparams.n_hidden != hparams.n_embed:\n",
    "            self.in_proj = Conv1D(hparams.n_embed, hparams.n_hidden)\n",
    "            self.out_proj = Conv1D(hparams.n_hidden, hparams.n_embed)\n",
    "        else:\n",
    "            self.in_proj = self.out_proj = None\n",
    "\n",
    "    def forward(self, x, past=None):\n",
    "        # Embedding\n",
    "        past_length = 0 if past is None else past.shape[-2]\n",
    "        batch_size, n_ctx = x.shape\n",
    "        position = position_for(batch_size, n_ctx, past_length, x.device)\n",
    "        h = self.wte(x) + self.wpe(position)\n",
    "        assert h.shape == (batch_size, n_ctx, self.hparams.n_embed)\n",
    "        if self.in_proj:\n",
    "            h = self.in_proj(h)\n",
    "        # Transformer\n",
    "        presents = []\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            if self.hparams.gradient_checkpointing:\n",
    "                h, present = torch.utils.checkpoint.checkpoint(block, h, past[:, i] if past is not None else None)\n",
    "            else:\n",
    "                h, present = block(h, past=past[:, i] if past is not None else None)\n",
    "            presents.append(present)\n",
    "        h = self.ln_f(h)\n",
    "        if self.out_proj:\n",
    "            h = self.out_proj(h)\n",
    "        # Output logits\n",
    "        h_flat = h.reshape([batch_size * n_ctx, self.hparams.n_embed])\n",
    "        logits = torch.matmul(h_flat, self.wte.weight.t())\n",
    "        logits = logits.reshape([batch_size, n_ctx, self.hparams.n_vocab])\n",
    "        return {\n",
    "            'presents': torch.stack(tuple(presents), dim=1),\n",
    "            'logits': logits,\n",
    "        }\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, hparams: HParams):\n",
    "        super().__init__()\n",
    "        self.ln_1 = Norm(hparams.n_hidden)\n",
    "        self.ln_2 = Norm(hparams.n_hidden)\n",
    "        self.mlp = MLP(hparams.n_hidden, hparams.n_hidden * 4)\n",
    "        self.attn = Attention(hparams)\n",
    "\n",
    "    def forward(self, x, past):\n",
    "        a, present = self.attn(self.ln_1(x), past=past)\n",
    "        x = x + a\n",
    "        m = self.mlp(self.ln_2(x))\n",
    "        x = x + m\n",
    "        return x, present\n",
    "\n",
    "\n",
    "class Norm(nn.Module):\n",
    "    \"\"\" Normalize to mean = 0, std = 1, then do a diagonal affine transform.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, *, dim=-1, epsilon=1e-5):\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "        self.dim = dim\n",
    "        self.epsilon = epsilon\n",
    "        self.g = nn.Parameter(torch.ones(n_features))\n",
    "        self.b = nn.Parameter(torch.zeros(n_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.shape[-1] == self.n_features\n",
    "        u = torch.mean(x, dim=self.dim, keepdim=True)\n",
    "        xmu = x - u\n",
    "        s = torch.mean(xmu * xmu, dim=self.dim, keepdim=True)\n",
    "        return xmu * torch.rsqrt(s + self.epsilon) * self.g + self.b\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden):\n",
    "        super().__init__()\n",
    "        self.c_fc = Conv1D(n_features, n_hidden)\n",
    "        self.c_proj = Conv1D(n_hidden, n_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = gelu(self.c_fc(x))\n",
    "        x = self.c_proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hparams: HParams):\n",
    "        super().__init__()\n",
    "        assert hparams.n_hidden % hparams.n_head == 0\n",
    "        self.hparams = hparams\n",
    "        self.c_attn = Conv1D(hparams.n_hidden, hparams.n_hidden * 3)\n",
    "        self.c_proj = Conv1D(hparams.n_hidden, hparams.n_hidden)\n",
    "\n",
    "    def forward(self, x, past):\n",
    "        assert len(x.shape) == 3  # [batch, sequence, features]\n",
    "        assert x.shape[-1] == self.hparams.n_hidden\n",
    "        if past is not None:\n",
    "            # Should be [batch, 2, heads, sequence, features], where 2 is [k, v]\n",
    "            assert len(past.shape) == 5\n",
    "            assert past.shape[-1] == self.hparams.n_hidden\n",
    "        c = self.c_attn(x)\n",
    "        q, k, v = map(self.split_heads, torch.split(c, x.shape[-1], dim=2))\n",
    "        present = torch.stack([k, v], dim=1)\n",
    "        if past is not None:\n",
    "            pk, pv = past[:, 0], past[:, 1]\n",
    "            k = torch.cat([pk, k], dim=-2)\n",
    "            v = torch.cat([pv, v], dim=-2)\n",
    "        a = self.multihead_attn(q, k, v)\n",
    "        a = self.merge_heads(a)\n",
    "        a = self.c_proj(a)\n",
    "        return a, present\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        \"\"\" From [batch, sequence, features] to\n",
    "        [batch, heads, sequence, features].\n",
    "        \"\"\"\n",
    "        return self.split_states(x, self.hparams.n_head).permute(0, 2, 1, 3)\n",
    "\n",
    "    @staticmethod\n",
    "    def split_states(x, n):\n",
    "        \"\"\" Reshape the last dimension of x into [n, x.shape[-1]/n].\n",
    "        \"\"\"\n",
    "        *start, m = x.shape\n",
    "        return x.reshape(start + [n, m // n])\n",
    "\n",
    "    def merge_heads(self, x):\n",
    "        \"\"\" Reverse of split_heads.\n",
    "        \"\"\"\n",
    "        return self.merge_states(x.permute(0, 2, 1, 3))\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_states(x):\n",
    "        \"\"\" Smash the last two dimensions of x into a single dimension.\n",
    "        \"\"\"\n",
    "        *start, a, b = x.shape\n",
    "        return x.reshape(start + [a * b])\n",
    "\n",
    "    def mask_attn_weights(self, w):\n",
    "        # w has shape [batch, heads, dst_sequence, src_sequence],\n",
    "        # where information flows from src to dst.\n",
    "        _, _, nd, ns = w.shape\n",
    "        b = self.attention_mask(nd, ns, dtype=w.dtype, device=w.device)\n",
    "        b = b.reshape((1, 1, nd, ns))\n",
    "        w = w * b - 1e10 * (1 - b)\n",
    "        return w\n",
    "\n",
    "    @staticmethod\n",
    "    def attention_mask(nd, ns, *, dtype, device=None):\n",
    "        \"\"\" 1's in the lower triangle, counting from the lower right corner.\n",
    "        Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd),\n",
    "        but doesn't produce garbage on TPUs.\n",
    "        \"\"\"\n",
    "        i = torch.arange(0, nd).unsqueeze(1)\n",
    "        j = torch.arange(ns)\n",
    "        return (i >= j - ns + nd).to(dtype=dtype, device=device)\n",
    "\n",
    "    def multihead_attn(self, q, k, v):\n",
    "        # q, k, v have shape [batch, heads, sequence, features]\n",
    "        w = torch.matmul(q, k.permute(0, 1, 3, 2))\n",
    "        w = w / math.sqrt(v.shape[-1])\n",
    "        w = self.mask_attn_weights(w)\n",
    "        w = F.softmax(w, dim=-1)\n",
    "        a = torch.matmul(w, v)\n",
    "        return a\n",
    "\n",
    "\n",
    "class Conv1D(nn.Linear):\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.weight, std=0.02)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "\n",
    "def gelu(x, c=math.sqrt(2 / math.pi)):\n",
    "    return 0.5 * x * (1 + torch.tanh(c * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "\n",
    "def position_for(batch_size, n_steps, past_length, device=None):\n",
    "    return (torch.arange(past_length, n_steps + past_length, device=device)\n",
    "            .unsqueeze(0).repeat(batch_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ModelWrapper:\n",
    " \n",
    "    UNK = '<unk>'\n",
    "    END_OF_LINE = '<endofline>'\n",
    "    END_OF_TEXT = '<endoftext>'\n",
    "\n",
    "    def __init__(self, model: Model, sp_model: spm.SentencePieceProcessor):\n",
    "        self.model = model\n",
    "        self.sp_model = sp_model\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, root: Path):\n",
    "        sp_model = spm.SentencePieceProcessor()\n",
    "        sp_model.load(str(root / 'sp.model'))\n",
    "        hparams = json.loads((root / 'params.json').read_text())['hparams']\n",
    "        hparams.setdefault('n_hidden', hparams['n_embed'])\n",
    "        model = Model(HParams(**hparams))\n",
    "        state = torch.load(root / 'model.pt', map_location='cpu')\n",
    "        state_dict = fixed_state_dict(state['state_dict'])\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "        tensor_list = list(state_dict.items())\n",
    "        for layer_tensor_name, tensor in tensor_list:\n",
    "            print(\"Layer %-42s: %9d elements\" % (layer_tensor_name, torch.numel(tensor)))\n",
    "        pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "        print (\"Total # params: %d\" % pytorch_total_params)\n",
    "\n",
    "        return cls(model, sp_model)\n",
    "\n",
    "    def tokenize(self, s: str) -> List[str]:\n",
    "        return self.sp_model.EncodeAsPieces(s)\n",
    "\n",
    "    def token_to_id(self, token: str) -> int:\n",
    "        return self.sp_model.PieceToId(token)\n",
    "\n",
    "    def id_to_token(self, token_id: int) -> str:\n",
    "        return self.sp_model.IdToPiece(int(token_id))\n",
    "\n",
    "    def get_log_probs(self, tokens: List[str]) -> torch.Tensor:\n",
    "        \"\"\" Return a tensor with shape (len(tokens), len(self.sp_model)),\n",
    "        with log-probabilities for tokens after each token in tokens.\n",
    "        If this is a start of the text, you may want to prepend END_OF_TEXT:\n",
    "        model.get_log_probs([model.END_OF_TEXT] + tokens).\n",
    "        Use model.tokenize to obtain tokens.\n",
    "        \"\"\"\n",
    "        assert len(tokens) <= self.model.hparams.n_ctx  # TODO\n",
    "        ids = [self.token_to_id(t) for t in tokens]\n",
    "        ctx = torch.LongTensor(ids).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(ctx)['logits'].squeeze(0)\n",
    "            return torch.log_softmax(logits, dim=1)\n",
    "\n",
    "    def get_occurred_log_probs(\n",
    "            self, tokens: List[str]) -> List[Tuple[float, str]]:\n",
    "        \"\"\" Return a list of log probs of actually occurred tokens,\n",
    "        starting from the second.\n",
    "        \"\"\"\n",
    "        log_probs = self.get_log_probs(tokens)\n",
    "        out = []\n",
    "        for idx, token in enumerate(tokens[1:]):\n",
    "            out.append((float(log_probs[idx, self.token_to_id(token)]), token))\n",
    "        return out\n",
    "\n",
    "    def get_next_top_k(\n",
    "            self, tokens: List[str], top_k: int) -> List[Tuple[float, str]]:\n",
    "        \"\"\" Return a list of top k tuples of log prob and token,\n",
    "        for what would come after the last token.\n",
    "        \"\"\"\n",
    "        next_log_probs = self.get_log_probs(tokens)[-1]\n",
    "        return sorted([(float(next_log_probs[i]), self.id_to_token(i))\n",
    "                       for i in next_log_probs.argsort()[-top_k:]],\n",
    "                      reverse=True)\n",
    "\n",
    "    def generate_tokens(self, tokens_prefix: List[str], tokens_to_generate: int, top_k: int) -> List[str]:\n",
    "\n",
    "        tokens = list(tokens_prefix)\n",
    "\n",
    "        for i in range(tokens_to_generate):\n",
    "\n",
    "            # generate TOP_K potential next tokens\n",
    "            ntk = self.get_next_top_k(tokens, top_k)\n",
    "\n",
    "            # convert log probs to real probs\n",
    "            logprobs = np.array(list(map(lambda a: a[0], ntk)))\n",
    "            probs = np.exp(logprobs) / np.exp(logprobs).sum()\n",
    "\n",
    "            # pick next token randomly according to probs distribution\n",
    "            next_token_n = np.random.choice(top_k, p=probs)\n",
    "            next_token = ntk[next_token_n][1]\n",
    "            # print (next_token)\n",
    "            \n",
    "            tokens.append(next_token)\n",
    "\n",
    "        return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_state_dict(state_dict):\n",
    "    if all(k.startswith('module.') for k in state_dict):\n",
    "        # legacy multi-GPU format\n",
    "        state_dict = {k[len('module.'):]: v for k, v in state_dict.items()}\n",
    "    return state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer wpe.weight                                :   1048576 elements\n",
      "Layer wte.weight                                :  51200000 elements\n",
      "Layer blocks.0.ln_1.g                           :      1024 elements\n",
      "Layer blocks.0.ln_1.b                           :      1024 elements\n",
      "Layer blocks.0.ln_2.g                           :      1024 elements\n",
      "Layer blocks.0.ln_2.b                           :      1024 elements\n",
      "Layer blocks.0.mlp.c_fc.weight                  :   4194304 elements\n",
      "Layer blocks.0.mlp.c_fc.bias                    :      4096 elements\n",
      "Layer blocks.0.mlp.c_proj.weight                :   4194304 elements\n",
      "Layer blocks.0.mlp.c_proj.bias                  :      1024 elements\n",
      "Layer blocks.0.attn.c_attn.weight               :   3145728 elements\n",
      "Layer blocks.0.attn.c_attn.bias                 :      3072 elements\n",
      "Layer blocks.0.attn.c_proj.weight               :   1048576 elements\n",
      "Layer blocks.0.attn.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.1.ln_1.g                           :      1024 elements\n",
      "Layer blocks.1.ln_1.b                           :      1024 elements\n",
      "Layer blocks.1.ln_2.g                           :      1024 elements\n",
      "Layer blocks.1.ln_2.b                           :      1024 elements\n",
      "Layer blocks.1.mlp.c_fc.weight                  :   4194304 elements\n",
      "Layer blocks.1.mlp.c_fc.bias                    :      4096 elements\n",
      "Layer blocks.1.mlp.c_proj.weight                :   4194304 elements\n",
      "Layer blocks.1.mlp.c_proj.bias                  :      1024 elements\n",
      "Layer blocks.1.attn.c_attn.weight               :   3145728 elements\n",
      "Layer blocks.1.attn.c_attn.bias                 :      3072 elements\n",
      "Layer blocks.1.attn.c_proj.weight               :   1048576 elements\n",
      "Layer blocks.1.attn.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.2.ln_1.g                           :      1024 elements\n",
      "Layer blocks.2.ln_1.b                           :      1024 elements\n",
      "Layer blocks.2.ln_2.g                           :      1024 elements\n",
      "Layer blocks.2.ln_2.b                           :      1024 elements\n",
      "Layer blocks.2.mlp.c_fc.weight                  :   4194304 elements\n",
      "Layer blocks.2.mlp.c_fc.bias                    :      4096 elements\n",
      "Layer blocks.2.mlp.c_proj.weight                :   4194304 elements\n",
      "Layer blocks.2.mlp.c_proj.bias                  :      1024 elements\n",
      "Layer blocks.2.attn.c_attn.weight               :   3145728 elements\n",
      "Layer blocks.2.attn.c_attn.bias                 :      3072 elements\n",
      "Layer blocks.2.attn.c_proj.weight               :   1048576 elements\n",
      "Layer blocks.2.attn.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.3.ln_1.g                           :      1024 elements\n",
      "Layer blocks.3.ln_1.b                           :      1024 elements\n",
      "Layer blocks.3.ln_2.g                           :      1024 elements\n",
      "Layer blocks.3.ln_2.b                           :      1024 elements\n",
      "Layer blocks.3.mlp.c_fc.weight                  :   4194304 elements\n",
      "Layer blocks.3.mlp.c_fc.bias                    :      4096 elements\n",
      "Layer blocks.3.mlp.c_proj.weight                :   4194304 elements\n",
      "Layer blocks.3.mlp.c_proj.bias                  :      1024 elements\n",
      "Layer blocks.3.attn.c_attn.weight               :   3145728 elements\n",
      "Layer blocks.3.attn.c_attn.bias                 :      3072 elements\n",
      "Layer blocks.3.attn.c_proj.weight               :   1048576 elements\n",
      "Layer blocks.3.attn.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.4.ln_1.g                           :      1024 elements\n",
      "Layer blocks.4.ln_1.b                           :      1024 elements\n",
      "Layer blocks.4.ln_2.g                           :      1024 elements\n",
      "Layer blocks.4.ln_2.b                           :      1024 elements\n",
      "Layer blocks.4.mlp.c_fc.weight                  :   4194304 elements\n",
      "Layer blocks.4.mlp.c_fc.bias                    :      4096 elements\n",
      "Layer blocks.4.mlp.c_proj.weight                :   4194304 elements\n",
      "Layer blocks.4.mlp.c_proj.bias                  :      1024 elements\n",
      "Layer blocks.4.attn.c_attn.weight               :   3145728 elements\n",
      "Layer blocks.4.attn.c_attn.bias                 :      3072 elements\n",
      "Layer blocks.4.attn.c_proj.weight               :   1048576 elements\n",
      "Layer blocks.4.attn.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.5.ln_1.g                           :      1024 elements\n",
      "Layer blocks.5.ln_1.b                           :      1024 elements\n",
      "Layer blocks.5.ln_2.g                           :      1024 elements\n",
      "Layer blocks.5.ln_2.b                           :      1024 elements\n",
      "Layer blocks.5.mlp.c_fc.weight                  :   4194304 elements\n",
      "Layer blocks.5.mlp.c_fc.bias                    :      4096 elements\n",
      "Layer blocks.5.mlp.c_proj.weight                :   4194304 elements\n",
      "Layer blocks.5.mlp.c_proj.bias                  :      1024 elements\n",
      "Layer blocks.5.attn.c_attn.weight               :   3145728 elements\n",
      "Layer blocks.5.attn.c_attn.bias                 :      3072 elements\n",
      "Layer blocks.5.attn.c_proj.weight               :   1048576 elements\n",
      "Layer blocks.5.attn.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.6.ln_1.g                           :      1024 elements\n",
      "Layer blocks.6.ln_1.b                           :      1024 elements\n",
      "Layer blocks.6.ln_2.g                           :      1024 elements\n",
      "Layer blocks.6.ln_2.b                           :      1024 elements\n",
      "Layer blocks.6.mlp.c_fc.weight                  :   4194304 elements\n",
      "Layer blocks.6.mlp.c_fc.bias                    :      4096 elements\n",
      "Layer blocks.6.mlp.c_proj.weight                :   4194304 elements\n",
      "Layer blocks.6.mlp.c_proj.bias                  :      1024 elements\n",
      "Layer blocks.6.attn.c_attn.weight               :   3145728 elements\n",
      "Layer blocks.6.attn.c_attn.bias                 :      3072 elements\n",
      "Layer blocks.6.attn.c_proj.weight               :   1048576 elements\n",
      "Layer blocks.6.attn.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.7.ln_1.g                           :      1024 elements\n",
      "Layer blocks.7.ln_1.b                           :      1024 elements\n",
      "Layer blocks.7.ln_2.g                           :      1024 elements\n",
      "Layer blocks.7.ln_2.b                           :      1024 elements\n",
      "Layer blocks.7.mlp.c_fc.weight                  :   4194304 elements\n",
      "Layer blocks.7.mlp.c_fc.bias                    :      4096 elements\n",
      "Layer blocks.7.mlp.c_proj.weight                :   4194304 elements\n",
      "Layer blocks.7.mlp.c_proj.bias                  :      1024 elements\n",
      "Layer blocks.7.attn.c_attn.weight               :   3145728 elements\n",
      "Layer blocks.7.attn.c_attn.bias                 :      3072 elements\n",
      "Layer blocks.7.attn.c_proj.weight               :   1048576 elements\n",
      "Layer blocks.7.attn.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.8.ln_1.g                           :      1024 elements\n",
      "Layer blocks.8.ln_1.b                           :      1024 elements\n",
      "Layer blocks.8.ln_2.g                           :      1024 elements\n",
      "Layer blocks.8.ln_2.b                           :      1024 elements\n",
      "Layer blocks.8.mlp.c_fc.weight                  :   4194304 elements\n",
      "Layer blocks.8.mlp.c_fc.bias                    :      4096 elements\n",
      "Layer blocks.8.mlp.c_proj.weight                :   4194304 elements\n",
      "Layer blocks.8.mlp.c_proj.bias                  :      1024 elements\n",
      "Layer blocks.8.attn.c_attn.weight               :   3145728 elements\n",
      "Layer blocks.8.attn.c_attn.bias                 :      3072 elements\n",
      "Layer blocks.8.attn.c_proj.weight               :   1048576 elements\n",
      "Layer blocks.8.attn.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.9.ln_1.g                           :      1024 elements\n",
      "Layer blocks.9.ln_1.b                           :      1024 elements\n",
      "Layer blocks.9.ln_2.g                           :      1024 elements\n",
      "Layer blocks.9.ln_2.b                           :      1024 elements\n",
      "Layer blocks.9.mlp.c_fc.weight                  :   4194304 elements\n",
      "Layer blocks.9.mlp.c_fc.bias                    :      4096 elements\n",
      "Layer blocks.9.mlp.c_proj.weight                :   4194304 elements\n",
      "Layer blocks.9.mlp.c_proj.bias                  :      1024 elements\n",
      "Layer blocks.9.attn.c_attn.weight               :   3145728 elements\n",
      "Layer blocks.9.attn.c_attn.bias                 :      3072 elements\n",
      "Layer blocks.9.attn.c_proj.weight               :   1048576 elements\n",
      "Layer blocks.9.attn.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.10.ln_1.g                          :      1024 elements\n",
      "Layer blocks.10.ln_1.b                          :      1024 elements\n",
      "Layer blocks.10.ln_2.g                          :      1024 elements\n",
      "Layer blocks.10.ln_2.b                          :      1024 elements\n",
      "Layer blocks.10.mlp.c_fc.weight                 :   4194304 elements\n",
      "Layer blocks.10.mlp.c_fc.bias                   :      4096 elements\n",
      "Layer blocks.10.mlp.c_proj.weight               :   4194304 elements\n",
      "Layer blocks.10.mlp.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.10.attn.c_attn.weight              :   3145728 elements\n",
      "Layer blocks.10.attn.c_attn.bias                :      3072 elements\n",
      "Layer blocks.10.attn.c_proj.weight              :   1048576 elements\n",
      "Layer blocks.10.attn.c_proj.bias                :      1024 elements\n",
      "Layer blocks.11.ln_1.g                          :      1024 elements\n",
      "Layer blocks.11.ln_1.b                          :      1024 elements\n",
      "Layer blocks.11.ln_2.g                          :      1024 elements\n",
      "Layer blocks.11.ln_2.b                          :      1024 elements\n",
      "Layer blocks.11.mlp.c_fc.weight                 :   4194304 elements\n",
      "Layer blocks.11.mlp.c_fc.bias                   :      4096 elements\n",
      "Layer blocks.11.mlp.c_proj.weight               :   4194304 elements\n",
      "Layer blocks.11.mlp.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.11.attn.c_attn.weight              :   3145728 elements\n",
      "Layer blocks.11.attn.c_attn.bias                :      3072 elements\n",
      "Layer blocks.11.attn.c_proj.weight              :   1048576 elements\n",
      "Layer blocks.11.attn.c_proj.bias                :      1024 elements\n",
      "Layer blocks.12.ln_1.g                          :      1024 elements\n",
      "Layer blocks.12.ln_1.b                          :      1024 elements\n",
      "Layer blocks.12.ln_2.g                          :      1024 elements\n",
      "Layer blocks.12.ln_2.b                          :      1024 elements\n",
      "Layer blocks.12.mlp.c_fc.weight                 :   4194304 elements\n",
      "Layer blocks.12.mlp.c_fc.bias                   :      4096 elements\n",
      "Layer blocks.12.mlp.c_proj.weight               :   4194304 elements\n",
      "Layer blocks.12.mlp.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.12.attn.c_attn.weight              :   3145728 elements\n",
      "Layer blocks.12.attn.c_attn.bias                :      3072 elements\n",
      "Layer blocks.12.attn.c_proj.weight              :   1048576 elements\n",
      "Layer blocks.12.attn.c_proj.bias                :      1024 elements\n",
      "Layer blocks.13.ln_1.g                          :      1024 elements\n",
      "Layer blocks.13.ln_1.b                          :      1024 elements\n",
      "Layer blocks.13.ln_2.g                          :      1024 elements\n",
      "Layer blocks.13.ln_2.b                          :      1024 elements\n",
      "Layer blocks.13.mlp.c_fc.weight                 :   4194304 elements\n",
      "Layer blocks.13.mlp.c_fc.bias                   :      4096 elements\n",
      "Layer blocks.13.mlp.c_proj.weight               :   4194304 elements\n",
      "Layer blocks.13.mlp.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.13.attn.c_attn.weight              :   3145728 elements\n",
      "Layer blocks.13.attn.c_attn.bias                :      3072 elements\n",
      "Layer blocks.13.attn.c_proj.weight              :   1048576 elements\n",
      "Layer blocks.13.attn.c_proj.bias                :      1024 elements\n",
      "Layer blocks.14.ln_1.g                          :      1024 elements\n",
      "Layer blocks.14.ln_1.b                          :      1024 elements\n",
      "Layer blocks.14.ln_2.g                          :      1024 elements\n",
      "Layer blocks.14.ln_2.b                          :      1024 elements\n",
      "Layer blocks.14.mlp.c_fc.weight                 :   4194304 elements\n",
      "Layer blocks.14.mlp.c_fc.bias                   :      4096 elements\n",
      "Layer blocks.14.mlp.c_proj.weight               :   4194304 elements\n",
      "Layer blocks.14.mlp.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.14.attn.c_attn.weight              :   3145728 elements\n",
      "Layer blocks.14.attn.c_attn.bias                :      3072 elements\n",
      "Layer blocks.14.attn.c_proj.weight              :   1048576 elements\n",
      "Layer blocks.14.attn.c_proj.bias                :      1024 elements\n",
      "Layer blocks.15.ln_1.g                          :      1024 elements\n",
      "Layer blocks.15.ln_1.b                          :      1024 elements\n",
      "Layer blocks.15.ln_2.g                          :      1024 elements\n",
      "Layer blocks.15.ln_2.b                          :      1024 elements\n",
      "Layer blocks.15.mlp.c_fc.weight                 :   4194304 elements\n",
      "Layer blocks.15.mlp.c_fc.bias                   :      4096 elements\n",
      "Layer blocks.15.mlp.c_proj.weight               :   4194304 elements\n",
      "Layer blocks.15.mlp.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.15.attn.c_attn.weight              :   3145728 elements\n",
      "Layer blocks.15.attn.c_attn.bias                :      3072 elements\n",
      "Layer blocks.15.attn.c_proj.weight              :   1048576 elements\n",
      "Layer blocks.15.attn.c_proj.bias                :      1024 elements\n",
      "Layer blocks.16.ln_1.g                          :      1024 elements\n",
      "Layer blocks.16.ln_1.b                          :      1024 elements\n",
      "Layer blocks.16.ln_2.g                          :      1024 elements\n",
      "Layer blocks.16.ln_2.b                          :      1024 elements\n",
      "Layer blocks.16.mlp.c_fc.weight                 :   4194304 elements\n",
      "Layer blocks.16.mlp.c_fc.bias                   :      4096 elements\n",
      "Layer blocks.16.mlp.c_proj.weight               :   4194304 elements\n",
      "Layer blocks.16.mlp.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.16.attn.c_attn.weight              :   3145728 elements\n",
      "Layer blocks.16.attn.c_attn.bias                :      3072 elements\n",
      "Layer blocks.16.attn.c_proj.weight              :   1048576 elements\n",
      "Layer blocks.16.attn.c_proj.bias                :      1024 elements\n",
      "Layer blocks.17.ln_1.g                          :      1024 elements\n",
      "Layer blocks.17.ln_1.b                          :      1024 elements\n",
      "Layer blocks.17.ln_2.g                          :      1024 elements\n",
      "Layer blocks.17.ln_2.b                          :      1024 elements\n",
      "Layer blocks.17.mlp.c_fc.weight                 :   4194304 elements\n",
      "Layer blocks.17.mlp.c_fc.bias                   :      4096 elements\n",
      "Layer blocks.17.mlp.c_proj.weight               :   4194304 elements\n",
      "Layer blocks.17.mlp.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.17.attn.c_attn.weight              :   3145728 elements\n",
      "Layer blocks.17.attn.c_attn.bias                :      3072 elements\n",
      "Layer blocks.17.attn.c_proj.weight              :   1048576 elements\n",
      "Layer blocks.17.attn.c_proj.bias                :      1024 elements\n",
      "Layer blocks.18.ln_1.g                          :      1024 elements\n",
      "Layer blocks.18.ln_1.b                          :      1024 elements\n",
      "Layer blocks.18.ln_2.g                          :      1024 elements\n",
      "Layer blocks.18.ln_2.b                          :      1024 elements\n",
      "Layer blocks.18.mlp.c_fc.weight                 :   4194304 elements\n",
      "Layer blocks.18.mlp.c_fc.bias                   :      4096 elements\n",
      "Layer blocks.18.mlp.c_proj.weight               :   4194304 elements\n",
      "Layer blocks.18.mlp.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.18.attn.c_attn.weight              :   3145728 elements\n",
      "Layer blocks.18.attn.c_attn.bias                :      3072 elements\n",
      "Layer blocks.18.attn.c_proj.weight              :   1048576 elements\n",
      "Layer blocks.18.attn.c_proj.bias                :      1024 elements\n",
      "Layer blocks.19.ln_1.g                          :      1024 elements\n",
      "Layer blocks.19.ln_1.b                          :      1024 elements\n",
      "Layer blocks.19.ln_2.g                          :      1024 elements\n",
      "Layer blocks.19.ln_2.b                          :      1024 elements\n",
      "Layer blocks.19.mlp.c_fc.weight                 :   4194304 elements\n",
      "Layer blocks.19.mlp.c_fc.bias                   :      4096 elements\n",
      "Layer blocks.19.mlp.c_proj.weight               :   4194304 elements\n",
      "Layer blocks.19.mlp.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.19.attn.c_attn.weight              :   3145728 elements\n",
      "Layer blocks.19.attn.c_attn.bias                :      3072 elements\n",
      "Layer blocks.19.attn.c_proj.weight              :   1048576 elements\n",
      "Layer blocks.19.attn.c_proj.bias                :      1024 elements\n",
      "Layer blocks.20.ln_1.g                          :      1024 elements\n",
      "Layer blocks.20.ln_1.b                          :      1024 elements\n",
      "Layer blocks.20.ln_2.g                          :      1024 elements\n",
      "Layer blocks.20.ln_2.b                          :      1024 elements\n",
      "Layer blocks.20.mlp.c_fc.weight                 :   4194304 elements\n",
      "Layer blocks.20.mlp.c_fc.bias                   :      4096 elements\n",
      "Layer blocks.20.mlp.c_proj.weight               :   4194304 elements\n",
      "Layer blocks.20.mlp.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.20.attn.c_attn.weight              :   3145728 elements\n",
      "Layer blocks.20.attn.c_attn.bias                :      3072 elements\n",
      "Layer blocks.20.attn.c_proj.weight              :   1048576 elements\n",
      "Layer blocks.20.attn.c_proj.bias                :      1024 elements\n",
      "Layer blocks.21.ln_1.g                          :      1024 elements\n",
      "Layer blocks.21.ln_1.b                          :      1024 elements\n",
      "Layer blocks.21.ln_2.g                          :      1024 elements\n",
      "Layer blocks.21.ln_2.b                          :      1024 elements\n",
      "Layer blocks.21.mlp.c_fc.weight                 :   4194304 elements\n",
      "Layer blocks.21.mlp.c_fc.bias                   :      4096 elements\n",
      "Layer blocks.21.mlp.c_proj.weight               :   4194304 elements\n",
      "Layer blocks.21.mlp.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.21.attn.c_attn.weight              :   3145728 elements\n",
      "Layer blocks.21.attn.c_attn.bias                :      3072 elements\n",
      "Layer blocks.21.attn.c_proj.weight              :   1048576 elements\n",
      "Layer blocks.21.attn.c_proj.bias                :      1024 elements\n",
      "Layer blocks.22.ln_1.g                          :      1024 elements\n",
      "Layer blocks.22.ln_1.b                          :      1024 elements\n",
      "Layer blocks.22.ln_2.g                          :      1024 elements\n",
      "Layer blocks.22.ln_2.b                          :      1024 elements\n",
      "Layer blocks.22.mlp.c_fc.weight                 :   4194304 elements\n",
      "Layer blocks.22.mlp.c_fc.bias                   :      4096 elements\n",
      "Layer blocks.22.mlp.c_proj.weight               :   4194304 elements\n",
      "Layer blocks.22.mlp.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.22.attn.c_attn.weight              :   3145728 elements\n",
      "Layer blocks.22.attn.c_attn.bias                :      3072 elements\n",
      "Layer blocks.22.attn.c_proj.weight              :   1048576 elements\n",
      "Layer blocks.22.attn.c_proj.bias                :      1024 elements\n",
      "Layer blocks.23.ln_1.g                          :      1024 elements\n",
      "Layer blocks.23.ln_1.b                          :      1024 elements\n",
      "Layer blocks.23.ln_2.g                          :      1024 elements\n",
      "Layer blocks.23.ln_2.b                          :      1024 elements\n",
      "Layer blocks.23.mlp.c_fc.weight                 :   4194304 elements\n",
      "Layer blocks.23.mlp.c_fc.bias                   :      4096 elements\n",
      "Layer blocks.23.mlp.c_proj.weight               :   4194304 elements\n",
      "Layer blocks.23.mlp.c_proj.bias                 :      1024 elements\n",
      "Layer blocks.23.attn.c_attn.weight              :   3145728 elements\n",
      "Layer blocks.23.attn.c_attn.bias                :      3072 elements\n",
      "Layer blocks.23.attn.c_proj.weight              :   1048576 elements\n",
      "Layer blocks.23.attn.c_proj.bias                :      1024 elements\n",
      "Layer ln_f.g                                    :      1024 elements\n",
      "Layer ln_f.b                                    :      1024 elements\n",
      "Total # params: 354560000\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/cgawron/gpt2-german/de345-root\"\n",
    "\n",
    "mw = ModelWrapper.load(Path(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(text, tokens_to_generate=100, top_k=8):\n",
    "    tokens = mw.tokenize(text)\n",
    "\n",
    "    tokens_gen = mw.generate_tokens(tokens, tokens_to_generate, top_k)\n",
    "    print(mw.sp_model.DecodePieces(tokens_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warum hat Verkehrsminister Andreas Scheuer die Verträge über die Pkw-Maut trotz aller Bedenken noch abgeschlossen, bevor der Europäische Gerichtshof diese Maut für unrechtsmäßig erklärt hat, und so einen Schaden von geschätzten 500 Millionen angerichtet? Und warum wurden Gespräche der Ministeriumsspitze mit den Betreiberfirmen nicht protokolliert? Die AfD will mit ihrer Anti-Islam-Initiative \"Mut gegen Vielfalt\" den Islam bekämpfen. Die Partei will mit der Aktion die Diskriminierung von Muslimen bekämpfen. Die Anti-Islam-Initiative \"Mut gegen Vielfalt\" ist ein Zusammenschluss verschiedener Anti-Islam-Organisationen. Die Partei \"Mut gegen Vielfalt\" (Mut gegen Vielfalt, Mut gegen Antisemitismus) will mit einer Anti-Islam-Initiative die Diskriminierung von Juden durch Einwanderer entgegentreten. Sie will mit der \"Mut gegen Vielfalt\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Warum hat Verkehrsminister Andreas Scheuer die Verträge über die Pkw-Maut\n",
    "trotz aller Bedenken noch abgeschlossen,\n",
    "bevor der Europäische Gerichtshof diese Maut für unrechtsmäßig erklärt hat,\n",
    "und so einen Schaden von geschätzten 500 Millionen angerichtet? \n",
    "Und warum wurden Gespräche der Ministeriumsspitze mit den Betreiberfirmen nicht protokolliert?\n",
    "\"\"\"\n",
    "\n",
    "generate_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Willi Brandt war, war der erste und bis in die 1970er-Jahre auch letzte Bürgermeister. Er war der erste Bürgermeister der Stadt Hannover. Nach seinem Tod wurde der Bau des Rathauses nach ihm benannt. Literatur * * Weblinks * Einzelnachweise Kategorie:Bürgermeister (Hannover) Kategorie:Mitglied der Hamburgischen Bürgerschaft Kategorie:CDU-Mitglied Kategorie:Deutscher Kategorie:Geboren 1887 Kategorie:Gestorben 1974 Kategorie:Mann Kategorie:Wikipedia:Artikel mit Video Kategorie:\n"
     ]
    }
   ],
   "source": [
    "generate_text(\"Willi Brandt war \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Fachhochschule Südwestfalen in Iserlohn ist eine der vier größten Fachhochschulen in Nordrhein-Westfalen. Sie gehört zum Verbund der Hochschulstudienplätze in Nordrhein-Westfalen. Die Hochschule Iserlohn ist Mitglied im Verbund der Hochschulrekturzwecke. Geschichte Die Hochschule Iserlohn wurde am 11. Oktober 1892 von der preußischen Regierung in Berlin als Kaiserliche Akademie für deutsche Sprache in Berlin gegründet. Sie ist benannt nach König Friedrich Wilhelm I. Die Wurzeln der Hochschule reichen weit ins frühe 20. Jahrhundert zurück. 1922 wurde sie in die neu gegründete\n"
     ]
    }
   ],
   "source": [
    "generate_text(\"Die Fachhochschule Südwestfalen in Iserlohn ist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der \"Budde-Preis\" wird einmal im Jahr an Absolventinnen und Absolventen der Fachhochschule Südwestfalen vergeben, die sich bei ihrer ingenieurwissenschaftlichen Studienabschlussarbeit durch hervorragende Leistungen ausgezeichnet haben. Die Abschlussarbeit soll sich durch außergewöhnlich innovative Ideen auszeichnen und ein hohes Maß an Kreativität erkennen lassen. Die Abschlussarbeiten werden durch eine Jury bewertet. Der Hauptpreis, ein Förderpreis für den Abschluss der Abschlussarbeit, wird von der Hochschule verliehen und besteht aus den drei besten Arbeiten für den Studienabschluss, sowie den fünf besten Arbeiten für die Abschlussprüfung. Die Gewinner sind die Universität Siegen selbst, die Hochschule für Angewandte Wissenschaften München, die Hochschule Bonn-Rhein-Sieg und der Landesbetrieb Hessen. Der BAFöG-Preis ist mit 25.000 Euro dotiert, der Deutsche Studienpreis mit 20.000 Euro. Der Förderpreis wird vom Deutschen Akadem\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Der \"Budde-Preis\" wird einmal im Jahr an Absolventinnen und Absolventen der Fachhochschule Südwestfalen vergeben, die sich bei ihrer ingenieurwissenschaftlichen Studienabschlussarbeit durch hervorragende Leistungen ausgezeichnet haben. Die Abschlussarbeit soll sich durch außergewöhnlich innovative Ideen auszeichnen und ein hohes Maß an Kreativität erkennen lassen. Die Abschlussarbeiten werden durch eine Jury bewertet.\"\"\"\n",
    "\n",
    "generate_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas Reimpell aus der 7a ist die einzige bekannte und auch die einzige in Deutschland noch erhaltene Orgel. Der Hauptbestandteil der Orgel befindet sich an der Westseite des Langhauses im Stil der Spätgotik. Der Chor ist aus drei Jochen und einem Hauptchor gebildet, die beiden anderen sind an den Chorschlusswänden im Langhaus zu finden. Die Chororgel wurde im Jahre 2005 von der Orgelbaufirma Kuhn aus Ludwigsburg erbaut und verfügt über 34 Register. * Koppeln: II/I, I/\n"
     ]
    }
   ],
   "source": [
    "generate_text(\"Thomas Reimpell aus der 7a ist \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir. Dass sie es aber nicht gibt. Wir sind ja kein Gericht. Es ist ein Gerichtssystem, dass die Gerichte entscheiden. Es ist ein Gerichtssystem, das von Gerichten entschieden werden muss und das sich nicht auf das Recht der Gerichte beschränkt. Ich finde, dass diese Gerichte nicht das Recht der Richter sind. Wir haben das Recht, Richter zu sein, das wir haben. Und das ist ein Gesetz. Das ist ein Gesetz. Wenn die Gerichte entscheiden, dass ein Richter nicht der rechtmäßige Richter sein kann,\n"
     ]
    }
   ],
   "source": [
    "generate_text(\"Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
