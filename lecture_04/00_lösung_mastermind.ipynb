{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musterlösung zur Aufgabe „Mastermind“\n",
    "\n",
    "Diese Musterlösung enthält einen *Code Maker* und einen (allerdings nicht optimalen) *Code Breaker*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "COLORS = ( 'r', 'g', 'b', 'o', 'w', 's')\n",
    "COUNT = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring\n",
    "\n",
    "Sowohl der *Code Maker* als auch der *Code Breaker* benötigen eine Funktion zur Bewertung eines Versuchs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(guess, secret, count=COUNT):\n",
    "    \"\"\" Evaluate a guess against the secret and return a tuple \n",
    "    containing the number of black and white pins. \n",
    "      \n",
    "    The secret and guess remain unchanged. \n",
    "    \n",
    "    >>> score(\"bbbb\", \"brrb\")\n",
    "    (2, 0)\n",
    "    >>> score(\"rbbr\", \"brrb\")\n",
    "    (0, 4)\n",
    "    >>> score(\"rbrb\", \"brrb\")\n",
    "    (2, 2)\n",
    "    \"\"\"\n",
    "    black, white = (0, 0)\n",
    "\n",
    "    # copy secret\n",
    "    secret = list(secret)\n",
    "\n",
    "    possible_whites = []\n",
    "    # count black pins\n",
    "    for i in range(count):\n",
    "        c = guess[i]\n",
    "        if secret[i] == c:\n",
    "            black += 1\n",
    "            secret[i] = None\n",
    "        else:\n",
    "            possible_whites.append(i)\n",
    "\n",
    "    # count white pins\n",
    "    for i in possible_whites:\n",
    "        c = guess[i]\n",
    "        if secret.count(c) > 0:\n",
    "            white += 1\n",
    "            secret.remove(c)\n",
    "\n",
    "    return (black, white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testen mit `doctest`\n",
    "\n",
    "Die merkwürdigen Kommentarzeilen sind Testfälle, die wir wie folgt aufrufen können:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    maker = CodeMaker()\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    len(maker.get_secret()) == COUNT\n",
      "Expecting:\n",
      "    True\n",
      "ok\n",
      "Trying:\n",
      "    maker = CodeMaker()\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    maker.score(maker.secret)\n",
      "Expecting:\n",
      "    (4, 0)\n",
      "ok\n",
      "Trying:\n",
      "    score(\"bbbb\", \"brrb\")\n",
      "Expecting:\n",
      "    (2, 0)\n",
      "ok\n",
      "Trying:\n",
      "    score(\"rbbr\", \"brrb\")\n",
      "Expecting:\n",
      "    (0, 4)\n",
      "ok\n",
      "Trying:\n",
      "    score(\"rbrb\", \"brrb\")\n",
      "Expecting:\n",
      "    (2, 2)\n",
      "ok\n",
      "7 items had no tests:\n",
      "    __main__\n",
      "    __main__.CodeBreaker\n",
      "    __main__.CodeBreaker.__init__\n",
      "    __main__.CodeBreaker.play\n",
      "    __main__.CodeMaker\n",
      "    __main__.CodeMaker.__init__\n",
      "    __main__.scorer\n",
      "3 items passed all tests:\n",
      "   2 tests in __main__.CodeMaker.get_secret\n",
      "   2 tests in __main__.CodeMaker.score\n",
      "   3 tests in __main__.score\n",
      "7 tests in 10 items.\n",
      "7 passed and 0 failed.\n",
      "Test passed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.testmod(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Maker\n",
    "\n",
    "Der *Code Maker* besteht im wesentlichen aus einer Methode zur Generierung des Codes und einer zur Bewertung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeMaker:\n",
    "    \"\"\" The code maker part: Choose a secret code and evaluate guesses. \"\"\"\n",
    "\n",
    "    def __init__(self, count=COUNT, colors=COLORS):\n",
    "        self.count = count\n",
    "        self.colors = list(colors)\n",
    "        self.secret = self.get_secret()\n",
    "\n",
    "    def get_secret(self):\n",
    "        \"\"\" Choose the secret code \n",
    "        \n",
    "        >>> maker = CodeMaker()\n",
    "        >>> len(maker.get_secret()) == COUNT\n",
    "        True\n",
    "        \"\"\"\n",
    "        secret = tuple([random.choice(self.colors) for i in range(self.count)])\n",
    "        return secret\n",
    "\n",
    "    def score(self, guess):\n",
    "        \"\"\" Evaluate a guess \n",
    "        \n",
    "        >>> maker = CodeMaker()\n",
    "        >>> maker.score(maker.secret)\n",
    "        (4, 0)\n",
    "        \"\"\"\n",
    "        return score(guess, self.secret, self.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Breaker\n",
    "\n",
    "Der *Code Breaker* benutzt einen sehr einfachen (und daher nicht optimalen) Algorithmus:\n",
    "- Nehme die Menge aller möglichen Codes.\n",
    "- Entferne die Codes, die mit den bisherigen Antworten des *Code Makers* im Widerspruch stehen. Dies sind die Codes, die im Vergleich mit den bisher geratenen Codes einen anderen Score ergeben als der vom *Code Maker* gegebene.\n",
    "- Probiere aus dieser Menge einen zufälligen Code.\n",
    "\n",
    "Ein besserer Algorithmus würde einen Code wählen, für den eine Antwort des *Code Makers* möglichst viel zusätzliche Information bringt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_CODES = { (a, b, c, d) for a  in COLORS for b in COLORS for c in COLORS for d in COLORS }\n",
    "\n",
    "class CodeBreaker:\n",
    "    \"\"\" The code breaker tries to guess the code. \"\"\"\n",
    "\n",
    "    def __init__(self, scorer, count=COUNT, colors=COLORS):\n",
    "        \"\"\" Create a code breaker with a scorer function \"\"\"\n",
    "        self.count = count\n",
    "        self.colors = list(colors)\n",
    "        self.scorer = scorer\n",
    "\n",
    "    def play(self): \n",
    "        \"\"\" Play a game using the scorer function.\n",
    "        \n",
    "        Returns the number of guesses needed to break the code.\n",
    "        \"\"\"\n",
    "        guesses = []\n",
    "        guesses.append(random.choice(list(ALL_CODES)))\n",
    "        scores = { guesses[0]: scorer(guesses[0]) }\n",
    "        if scores[guesses[0]][0] == self.count:\n",
    "            return 1\n",
    "\n",
    "        candidates = set(ALL_CODES) - set(guesses)\n",
    "        while len(candidates) > 0:\n",
    "            invalid = set()\n",
    "            for candidate in candidates:\n",
    "                # check whether the candidate is consistent with the guesses we made\n",
    "                # a consistent candidate should reproduce the scores we already got\n",
    "\n",
    "                for guess in guesses:\n",
    "                    sc = score(guess, candidate, self.count)\n",
    "                    if sc != scores[guess]:\n",
    "                       # different score - the candidate is not consistent with what we know\n",
    "                       invalid.add(candidate) \n",
    "                       break\n",
    "             \n",
    "            candidates -= invalid\n",
    "            candidate = random.choice(list(candidates))\n",
    "\n",
    "            guesses.append(candidate)\n",
    "            scores[candidate] = scorer(candidate)\n",
    "            if scores[candidate][0] == self.count:\n",
    "                return len(guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswertung\n",
    "\n",
    "Wir spielen nun 1000 Partien und werten aus, wie viele Versuche der *Code Breaker* benötigt hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guessed in 1: 1\n",
      "guessed in 2: 11\n",
      "guessed in 3: 73\n",
      "guessed in 4: 340\n",
      "guessed in 5: 426\n",
      "guessed in 6: 138\n",
      "guessed in 7: 11\n",
      "average guesses needed: 4.64\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "sum = 0\n",
    "stat = dict()\n",
    "\n",
    "for i in range(N):\n",
    "    coder = CodeMaker()\n",
    "\n",
    "    def scorer(guess):\n",
    "        res = coder.score(guess)\n",
    "        return res\n",
    "\n",
    "    breaker = CodeBreaker(scorer)\n",
    "    rounds = breaker.play()\n",
    "    sum += rounds\n",
    "    if rounds in stat:\n",
    "        stat[rounds] += 1\n",
    "    else:\n",
    "        stat[rounds] = 1\n",
    "\n",
    "for i in sorted(stat.keys()):\n",
    "    print(f\"guessed in {i}: {stat[i]}\")\n",
    "print(f\"average guesses needed: {sum/N:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
