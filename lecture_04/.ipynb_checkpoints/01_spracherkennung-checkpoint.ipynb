{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendungsbeispiel:  Texte mit Python analysieren\n",
    "\n",
    "## Erkennung der Sprache anhand der Häufigkeit von Buchstaben und n-Grammen\n",
    "\n",
    "Wir wollen uns heute mit der statistischen Auswertung von Texten beschäftigen und Versuchen, die Zugehörigkeit eines Textes zu einer Sprache anhand der Verteilung von Buchstaben und *n-Grammen* zu bestimmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(word, n):\n",
    "    \"\"\" Generiere alle n-Gramme eines Wortes \"\"\"\n",
    "    if len(word) < n:\n",
    "        yield word\n",
    "    for index in range(len(word) - (n - 1)): \n",
    "        yield word[index:index+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ g for g in ngrams('Py', 3) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distribution:\n",
    "    \"\"\" Generiere eine Statistik für Buchstaben oder n-Gramme \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.counter = dict()\n",
    "        self.count = 0\n",
    "        \n",
    "    def add(self, iter):\n",
    "        \"\"\" Füge Elemente aus iter hinzu \"\"\"\n",
    "        for x in iter:\n",
    "            self.count += 1\n",
    "            if x in self.counter:\n",
    "                self.counter[x] += 1\n",
    "            else:\n",
    "                self.counter[x] = 1\n",
    "    \n",
    "    def normalize(self):\n",
    "        \"\"\" Gebe normalisierte Verteilung zurück \"\"\"\n",
    "        return { k:c/self.count for (k, c) in self.counter.items() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def read_dict(name):\n",
    "    \"\"\" Lese das Wörterbuch `name` und erstelle eine Statistik der Buchstabenhäufigkeit.\n",
    "        Das Wörterbuch sollte je Zeile ein Wort enthalten und in UTF-8 kodiert sein.\n",
    "    \"\"\"\n",
    "    letters = Distribution()\n",
    "    bigrams = Distribution()\n",
    "    words = 0\n",
    "\n",
    "    start = time.time()\n",
    "    with open(name, 'r') as file:\n",
    "        for word in file:\n",
    "            word = word[:-1].lower()\n",
    "            words += 1\n",
    "            \n",
    "            letters.add(word)\n",
    "            bigrams.add(ngrams(word, 2))\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"read {words:,d} words [{letters.count:,d} chars, {bigrams.count:,d} bigrams] from {name} in {end - start:.1f} seconds\")\n",
    "    return (letters.normalize(), bigrams.normalize())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GERMAN = read_dict('german.txt')\n",
    "ENGLISH = read_dict('english.txt')\n",
    "SPANISH = read_dict('español.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "for c in sorted(GERMAN[0].items(), key=operator.itemgetter(1), reverse=True)[:10]:\n",
    "    print(f\"{c[0]} => Deutsch: {100*GERMAN[0][c[0]]:5.2f} %  English: {100*ENGLISH[0][c[0]]:5.2f} %  Spanisch: {100*SPANISH[0][c[0]]:5.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in sorted(GERMAN[1].items(), key=operator.itemgetter(1), reverse=True)[:10]:\n",
    "    print(f\"{c[0]} => Deutsch: {100*GERMAN[1][c[0]]:5.2f} %  English: {100*ENGLISH[1][c[0]]:5.2f} %  Spanisch: {100*SPANISH[1][c[0]]:5.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "\n",
    "def euclid(a, b):\n",
    "    \"\"\" Berechne den euklidischen Abstand zweier normalisierten Verteilungen \"\"\"\n",
    "    sum = 0\n",
    "\n",
    "    # Erst die Schnittmenge\n",
    "    for x in a.keys() & b.keys():\n",
    "        sum += (a[x] - b[x])**2\n",
    "\n",
    "    # Dann die Differenzmengen\n",
    "    for x in a.keys() - b.keys():\n",
    "        sum += a[x] * a[x]\n",
    "    for x in b.keys() - a.keys():\n",
    "        sum += b[x] * b[x]\n",
    "\n",
    "    return math.sqrt(sum)\n",
    "   \n",
    "def hellinger(a, b):\n",
    "    \"\"\" Berechne die Hellinger-Distanz zweier normalisierter Verteilungen \"\"\"\n",
    "    sum = 0\n",
    "\n",
    "    # Erst die Schnittmenge\n",
    "    for x in a.keys() & b.keys():\n",
    "        sum += 0.5 * (math.sqrt(a[x]) - math.sqrt(b[x]))**2\n",
    "\n",
    "    # Dann die Differenzmengen\n",
    "    for x in a.keys() - b.keys():\n",
    "        sum += 0.5 * a[x]\n",
    "    for x in b.keys() - a.keys():\n",
    "        sum += 0.5 * b[x]\n",
    "\n",
    "    return math.sqrt(sum)\n",
    "\n",
    "\n",
    "def analyze(text):\n",
    "    \"\"\" Analysiere Text und berechne den Abstand zu den Sprachen \"\"\"\n",
    "    letters = Distribution()\n",
    "    bigrams = Distribution()\n",
    "    \n",
    "    text = text.lower()\n",
    "    for word in re.sub(\"[^\\w]+\", \" \", text).split():\n",
    "        letters.add(word)\n",
    "        bigrams.add(ngrams(word, 2))\n",
    "            \n",
    "     \n",
    "    delta = dict()\n",
    "    for (lang, dist) in [ ('Deutsch', GERMAN), ('Englisch', ENGLISH), ('Spanisch', SPANISH) ]:\n",
    "        delta[lang] = ( euclid(letters.normalize(), dist[0]), hellinger(letters.normalize(), dist[0]),\n",
    "                        euclid(bigrams.normalize(), dist[1]), hellinger(bigrams.normalize(), dist[1]) ) \n",
    "        \n",
    "    return delta\n",
    "\n",
    "def print_report(delta):\n",
    "    \"\"\" Gebe Resultate aus \"\"\"\n",
    "    ranking = { lang : val[3] for (lang, val) in delta.items() }\n",
    "    ranking = sorted(ranking.items(), key=operator.itemgetter(1))\n",
    "    \n",
    "    print(f\"Der Text ist wahrscheinlich {ranking[0][0]}\")\n",
    "    print()\n",
    "    print(\"Buchstaben:\")\n",
    "    for res in ranking:\n",
    "        lang = res[0]\n",
    "        print(f\"    Sprache: {lang:8} Euklidischer Abstand: {delta[lang][0]:.2f}  Hellinger-Abstand: {delta[lang][1]:.2f}\")\n",
    "\n",
    "    print(\"Bigramme:\")\n",
    "    for res in ranking:\n",
    "        lang = res[0]\n",
    "        print(f\"    Sprache: {lang:8} Euklidischer Abstand: {delta[lang][2]:.2f}  Hellinger-Abstand: {delta[lang][3]:.2f}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Stufen\", Hermann Hesse\n",
    "\n",
    "text = \"\"\"\n",
    "Wie jede Blüte welkt und jede Jugend\n",
    "Dem Alter weicht, blüht jede Lebensstufe,\n",
    "Blüht jede Weisheit auch und jede Tugend\n",
    "Zu ihrer Zeit und darf nicht ewig dauern.\n",
    "\n",
    "Es muß das Herz bei jedem Lebensrufe\n",
    "Bereit zum Abschied sein und Neubeginne,\n",
    "Um sich in Tapferkeit und ohne Trauern\n",
    "In andre, neue Bindungen zu geben.\n",
    "\n",
    "Und jedem Anfang wohnt ein Zauber inne,\n",
    "Der uns beschützt und der uns hilft, zu leben.\n",
    "\n",
    "Wir sollen heiter Raum um Raum durchschreiten,\n",
    "An keinem wie an einer Heimat hängen,\n",
    "Der Weltgeist will nicht fesseln uns und engen,\n",
    "Er will uns Stuf' um Stufe heben, weiten.\n",
    "\n",
    "Kaum sind wir heimisch einem Lebenskreise\n",
    "Und traulich eingewohnt, so droht Erschlaffen,\n",
    "Nur wer bereit zu Aufbruch ist und Reise,\n",
    "Mag lähmender Gewöhnung sich entraffen.\n",
    "\n",
    "Es wird vielleicht auch noch die Todesstunde\n",
    "Uns neuen Räumen jung entgegensenden,\n",
    "Des Lebens Ruf an uns wird niemals enden ...\n",
    "Wohlan denn, Herz, nimm Abschied und gesunde!\n",
    "\"\"\"\n",
    "\n",
    "delta = analyze(text)\n",
    "print_report(delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"The road not taken\", Robert Frost\n",
    "\n",
    "text = \"\"\" \n",
    "Two roads diverged in a yellow wood,\n",
    "And sorry I could not travel both\n",
    "And be one traveler, long I stood\n",
    "And looked down one as far as I could\n",
    "To where it bent in the undergrowth;\n",
    "\n",
    "Then took the other, as just as fair,\n",
    "And having perhaps the better claim,\n",
    "Because it was grassy and wanted wear;\n",
    "Though as for that the passing there\n",
    "Had worn them really about the same,\n",
    "\n",
    "And both that morning equally lay\n",
    "In leaves no step had trodden black.\n",
    "Oh, I kept the first for another day!\n",
    "Yet knowing how way leads on to way,\n",
    "I doubted if I should ever come back.\n",
    "\n",
    "I shall be telling this with a sigh\n",
    "Somewhere ages and ages hence:\n",
    "Two roads diverged in a wood, and I—\n",
    "I took the one less traveled by,\n",
    "And that has made all the difference.\n",
    "\"\"\"\n",
    "\n",
    "delta = analyze(text)\n",
    "print_report(delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Cantares\", Antonio Machado\n",
    "\n",
    "text = \"\"\" \n",
    "Todo pasa y todo queda, \n",
    "pero lo nuestro es pasar, \n",
    "pasar haciendo caminos, \n",
    "caminos sobre el mar. \n",
    "\n",
    "Nunca perseguí la gloria, \n",
    "ni dejar en la memoria \n",
    "de los hombres mi canción; \n",
    "yo amo los mundos sutiles, \n",
    "ingrávidos y gentiles, \n",
    "como pompas de jabón. \n",
    "\n",
    "Me gusta verlos pintarse \n",
    "de sol y grana, volar \n",
    "bajo el cielo azul, temblar \n",
    "súbitamente y quebrarse... \n",
    "\n",
    "Nunca perseguí la gloria. \n",
    "\n",
    "Caminante, son tus huellas \n",
    "el camino y nada más; \n",
    "caminante, no hay camino, \n",
    "se hace camino al andar. \n",
    "\n",
    "Al andar se hace camino \n",
    "y al volver la vista atrás \n",
    "se ve la senda que nunca \n",
    "se ha de volver a pisar. \n",
    "\n",
    "Caminante no hay camino \n",
    "sino estelas en la mar... \n",
    "\n",
    "Hace algún tiempo en ese lugar \n",
    "donde hoy los bosques se visten de espinos \n",
    "se oyó la voz de un poeta gritar \n",
    "\"Caminante no hay camino, \n",
    "se hace camino al andar...\" \n",
    "\n",
    "Golpe a golpe, verso a verso... \n",
    "\n",
    "Murió el poeta lejos del hogar. \n",
    "Le cubre el polvo de un país vecino. \n",
    "Al alejarse le vieron llorar. \n",
    "\"Caminante no hay camino, \n",
    "se hace camino al andar...\" \n",
    "\n",
    "Golpe a golpe, verso a verso... \n",
    "\n",
    "Cuando el jilguero no puede cantar. \n",
    "Cuando el poeta es un peregrino, \n",
    "cuando de nada nos sirve rezar. \n",
    "\"Caminante no hay camino, \n",
    "se hace camino al andar...\" \n",
    "\n",
    "Golpe a golpe, verso a verso.\n",
    "\"\"\"\n",
    "\n",
    "delta = analyze(text)\n",
    "print_report(delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
